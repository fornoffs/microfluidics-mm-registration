{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports\n",
    "Run cell below to import necessary libraries and functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "import numpy as np\n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "# Local imports\n",
    "from timeseries_alignment.timeseries_alignment_framework import (\n",
    "    align_time_series, create_template_hough, ht_rotation_wrapper, \n",
    "    ht_prev_rotation_wrapper, orb_rotation_wrapper, orb_prev_rotation_wrapper, \n",
    "    orb_translation_wrapper, xcorr_translation_wrapper, align_time_series_multiprocessing\n",
    ")\n",
    "from timeseries_alignment.utils import (\n",
    "    apply_transformations,\n",
    "    measure_runtime, measure_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Loading\n",
    "Adjust file path (`img_path`) to point to your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset selection: adjust path to your data location\n",
    "\n",
    "# sample experimental dataset of 10 timepoints\n",
    "img_path = 'data/sample10timepoints.tif'    \n",
    "\n",
    "# Load image:\n",
    "img = AICSImage(img_path)\n",
    "img_data = img.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Template Creation\n",
    "\n",
    "Adjust channel index (`channel`) - ensure it's the phase contrast channel\n",
    "\n",
    "*Note: This step could be skipped and template creation done directly in Step 3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating template from first timepoint...\n",
      "✓ Template created successfully!\n",
      "✓ Detected rotation angle: 1.09°\n"
     ]
    }
   ],
   "source": [
    "# Select channel for template creation (typically phase contrast)\n",
    "channel = 0\n",
    "\n",
    "# Create template using HT rotation detection\n",
    "print(\"Creating template from first timepoint...\")\n",
    "template, detected_angle = create_template_hough(\n",
    "    img_data, \n",
    "    channel=channel, \n",
    "    plot=False, \n",
    "    t=0\n",
    ")\n",
    "\n",
    "print(f\"✓ Template created successfully!\")\n",
    "print(f\"✓ Detected rotation angle: {detected_angle:.2f}°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Image Registration\n",
    "\n",
    "Choose from rotation/translation methods (`rotation_method`/`translation_method`) mentioned below, set (`plot`) to True for debugging and quick visual verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running timeseries alignment...\n",
      "✓ Alignment completed! Processed 10 timepoints\n"
     ]
    }
   ],
   "source": [
    "# Available registration methods:\n",
    "# Rotation methods:\n",
    "#   - ht_rotation_wrapper: HT-based rotation\n",
    "#   - ht_prev_rotation_wrapper: HT-based rotation with temporal initialization\n",
    "#   - orb_rotation_wrapper: ORB-based rotation\n",
    "#   - orb_prev_rotation_wrapper: ORB-based rotation with temporal initialization\n",
    "# Translation methods:\n",
    "#   - orb_translation_wrapper: ORB-based translation\n",
    "#   - xcorr_translation_wrapper: Cross-correlation based translation\n",
    "\n",
    "# Preferred methods: ht_prev_rotation_wrapper and xcorr_translation_wrapper\n",
    "\n",
    "# Use channel=0 unless already defined\n",
    "if 'channel' not in locals():\n",
    "    channel = 0\n",
    "\n",
    "# Common parameters for registration\n",
    "align_params = {\n",
    "    'channel': channel,\n",
    "    'template': create_template_hough(img_data, channel=channel, plot=False, t=0),\n",
    "    'rotation_method': ht_prev_rotation_wrapper,\n",
    "    'translation_method': xcorr_translation_wrapper,\n",
    "    'plot': False,\n",
    "    'use_template_prev': True\n",
    "}\n",
    "\n",
    "print(\"Running timeseries alignment...\")\n",
    "detected_shifts, detected_angles = align_time_series(img_data, **align_params)\n",
    "print(f\"✓ Alignment completed! Processed {len(detected_angles)} timepoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save results\n",
    "\n",
    "Save resulting sample file as tiff in the same folder as the original img (mainly for visual verification, only saves single channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed image saved to: data/sample10timepoints_aligned.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data/sample10timepoints_aligned.tif'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_transformations(img_data, img_path, detected_shifts, detected_angles, channel=channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Measure runtime and memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0.2798 seconds\n",
      "Runtime: 0.2538 seconds\n",
      "Runtime: 0.2497 seconds\n",
      "Runtime: 0.2480 seconds\n",
      "Runtime: 0.2360 seconds\n",
      "Runtime: 0.2493 seconds\n",
      "Runtime: 0.2590 seconds\n",
      "Runtime: 0.2706 seconds\n",
      "Runtime: 0.2508 seconds\n",
      "Runtime: 0.2418 seconds\n",
      "\n",
      "Average runtime: 0.2539 seconds\n",
      "Stddev runtime: 0.0123 seconds\n",
      "Peak Memory Usage: 34.00 MB\n",
      "Peak Memory Usage: 34.00 MB\n",
      "Peak Memory Usage: 34.00 MB\n",
      "Peak Memory Usage: 34.00 MB\n",
      "Peak Memory Usage: 34.00 MB\n",
      "Peak Memory Usage: 34.00 MB\n",
      "Peak Memory Usage: 34.00 MB\n",
      "Peak Memory Usage: 34.00 MB\n",
      "Peak Memory Usage: 34.00 MB\n",
      "Peak Memory Usage: 34.00 MB\n",
      "\n",
      "Average peak memory: 34.0046 MB\n",
      "Stddev peak memory: 0.0002 MB\n"
     ]
    }
   ],
   "source": [
    "# Runtime measurements, 10 runs\n",
    "runtimes = []\n",
    "for i in range(10):\n",
    "    runtime = measure_runtime(align_time_series, img_data, **align_params)\n",
    "    runtimes.append(runtime)\n",
    "\n",
    "avg_runtime = np.mean(runtimes)\n",
    "std_runtime = np.std(runtimes)\n",
    "print(f\"\\nAverage runtime: {avg_runtime:.4f} seconds\")\n",
    "print(f\"Stddev runtime: {std_runtime:.4f} seconds\")\n",
    "\n",
    "# Memory measurements, 10 runs\n",
    "memory = []\n",
    "for i in range(10):\n",
    "    mem = measure_memory(align_time_series, img_data, **align_params)\n",
    "    memory.append(mem)\n",
    "\n",
    "avg_memory = np.mean(memory)\n",
    "std_memory = np.std(memory)\n",
    "print(f\"\\nAverage peak memory: {avg_memory:.4f} MB\")\n",
    "print(f\"Stddev peak memory: {std_memory:.4f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
